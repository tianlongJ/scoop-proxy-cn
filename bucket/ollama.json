{
  "version": "0.5.11",
  "description": "Get up and running with large language models locally.",
  "homepage": "https:ollama.com",
  "license": "MIT",
  "notes": "Ollama with deamon has been moved to 'extrasollama-full'.",
  "suggest": {
    "Ollama Full": "extrasollama-full"
  },
  "architecture": {
    "64bit": {
      "url": "https:github.comollamaollamareleasesdownloadv0.5.11ollama-windows-amd64.zip",
      "hash": "2dceec9154eceafe44ff83413a7c1b0b7e5f4bb26414dade25b13e3daa788f93"
    },
    "arm64": {
      "url": "https:github.comollamaollamareleasesdownloadv0.5.11ollama-windows-arm64.zip",
      "hash": "9d5a74599a33956cc9de3a89600c80a7d1d3023ad3ff94f79248a2534db57d16"
    }
  },
  "bin": "ollama.exe",
  "checkver": {
    "github": "https:github.comollamaollama"
  },
  "autoupdate": {
    "architecture": {
      "64bit": {
        "url": "https:github.comollamaollamareleasesdownloadv$versionollama-windows-amd64.zip"
      },
      "arm64": {
        "url": "https:github.comollamaollamareleasesdownloadv$versionollama-windows-arm64.zip"
      }
    },
    "hash": {
      "url": "$baseurlsha256sum.txt"
    }
  }
}